{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f50ca33",
      "metadata": {
        "id": "0f50ca33"
      },
      "source": [
        "# Comparing Trained LLM Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3298dcf",
      "metadata": {
        "id": "f3298dcf"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "a5e5a574",
      "metadata": {
        "height": 30,
        "id": "a5e5a574"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers>=4.46.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d517b64",
      "metadata": {
        "id": "8d517b64"
      },
      "source": [
        "**Importing Required Libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "f2f7198e",
      "metadata": {
        "height": 64,
        "id": "f2f7198e"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0fae72c",
      "metadata": {
        "id": "b0fae72c"
      },
      "source": [
        "## Tokenizing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03484cb1",
      "metadata": {
        "id": "03484cb1"
      },
      "source": [
        "**Importing Required Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "76f8c924",
      "metadata": {
        "height": 30,
        "id": "76f8c924"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "857e4407",
      "metadata": {
        "height": 47,
        "id": "857e4407"
      },
      "outputs": [],
      "source": [
        "# define the sentence to tokenize\n",
        "sentence = \"Hello world!\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bee9d115",
      "metadata": {
        "id": "bee9d115"
      },
      "source": [
        "**Understanding Tokenization in Language Models**\n",
        "\n",
        "This section demonstrates how different tokenizers process text, showing how tokenization impacts model efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "533f737f",
      "metadata": {
        "height": 62,
        "id": "533f737f"
      },
      "outputs": [],
      "source": [
        "# load the pretrained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "d4791980",
      "metadata": {
        "height": 62,
        "id": "d4791980"
      },
      "outputs": [],
      "source": [
        "# apply the tokenizer to the sentence and extract the token ids\n",
        "token_ids = tokenizer(sentence).input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "7d2cb1f0",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d2cb1f0",
        "outputId": "58aae4f9-ef66-4201-e83f-77047924adc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 8667, 1362, 106, 102]\n"
          ]
        }
      ],
      "source": [
        "print(token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d197eb8",
      "metadata": {
        "id": "6d197eb8"
      },
      "source": [
        "To map each token ID to its corresponding token, you can use the `decode` method of the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "a0c49ae1",
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0c49ae1",
        "outputId": "1e70df9f-9605-47c1-f19b-0c81c9913050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "Hello\n",
            "world\n",
            "!\n",
            "[SEP]\n"
          ]
        }
      ],
      "source": [
        "for id in token_ids:\n",
        "    print(tokenizer.decode(id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "b4e2f602",
      "metadata": {
        "height": 436,
        "id": "b4e2f602"
      },
      "outputs": [],
      "source": [
        "# A list of colors in RGB for representing the tokens\n",
        "colors = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence: str, tokenizer_name: str):\n",
        "    \"\"\" Show the tokens each separated by a different color \"\"\"\n",
        "\n",
        "    # Load the tokenizer and tokenize the input\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "\n",
        "    # Extract vocabulary length\n",
        "    print(f\"Vocab length: {len(tokenizer)}\")\n",
        "\n",
        "    # Print a colored list of tokens\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        print(\n",
        "            f'\\x1b[0;30;48;2;{colors[idx % len(colors)]}m' +\n",
        "            tokenizer.decode(t) +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d69a9962",
      "metadata": {
        "id": "d69a9962"
      },
      "source": [
        "Here's the text that you'll use to explore the different tokenization strategies of each model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa6a63a",
      "metadata": {
        "id": "efa6a63a"
      },
      "source": [
        "**Conditional Statements**\n",
        "\n",
        "This code snippet applies conditional logic to control the execution flow based on certain conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "512aa2d7",
      "metadata": {
        "height": 130,
        "id": "512aa2d7"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "🎵 鸟\n",
        "show_tokens False None elif == >= else: two tabs:\"    \" Three tabs: \"       \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00bd4cd",
      "metadata": {
        "id": "d00bd4cd"
      },
      "source": [
        "**bert-base-cased**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "44ce3097",
      "metadata": {
        "height": 30,
        "id": "44ce3097"
      },
      "outputs": [],
      "source": [
        "#show_tokens(text, \"bert-base-cased\")\n",
        "import textwrap\n",
        "\n",
        "def show_tokens(sentence: str, tokenizer_name: str, wrap_width: int = 250):\n",
        "    \"\"\" Show the tokens each separated by a different color, wrapping at wrap_width \"\"\"\n",
        "\n",
        "    # Load the tokenizer and tokenize the input\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "\n",
        "    # Extract vocabulary length\n",
        "    print(f\"Vocab length: {len(tokenizer)}\")\n",
        "\n",
        "    # Print a colored list of tokens, wrapping the output\n",
        "    token_strings = [\n",
        "        f'\\x1b[0;30;48;2;{colors[idx % len(colors)]}m' +\n",
        "        tokenizer.decode(t) +\n",
        "        '\\x1b[0m'\n",
        "        for idx, t in enumerate(token_ids)\n",
        "    ]\n",
        "\n",
        "    wrapped_text = textwrap.fill(\" \".join(token_strings), width=wrap_width)\n",
        "    print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "7f08133d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 30,
        "id": "7f08133d",
        "outputId": "bbac1be7-f148-4753-8c13-0087bd2ee93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 30522\n",
            "\u001b[0;30;48;2;102;194;165m[CLS]\u001b[0m \u001b[0;30;48;2;252;141;98menglish\u001b[0m \u001b[0;30;48;2;141;160;203mand\u001b[0m \u001b[0;30;48;2;231;138;195mcapital\u001b[0m \u001b[0;30;48;2;166;216;84m##ization\u001b[0m \u001b[0;30;48;2;255;217;47m[UNK]\u001b[0m \u001b[0;30;48;2;102;194;165m[UNK]\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_\u001b[0m \u001b[0;30;48;2;231;138;195mtoken\u001b[0m \u001b[0;30;48;2;166;216;84m##s\u001b[0m \u001b[0;30;48;2;255;217;47mfalse\u001b[0m \u001b[0;30;48;2;102;194;165mnone\u001b[0m \u001b[0;30;48;2;252;141;98meli\u001b[0m\n",
            "\u001b[0;30;48;2;141;160;203m##f\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m \u001b[0;30;48;2;255;217;47m>\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98melse\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m \u001b[0;30;48;2;231;138;195mtwo\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84mtab\u001b[0m \u001b[0;30;48;2;255;217;47m##s\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m\"\u001b[0m \u001b[0;30;48;2;141;160;203m\"\u001b[0m \u001b[0;30;48;2;231;138;195mthree\u001b[0m \u001b[0;30;48;2;166;216;84mtab\u001b[0m \u001b[0;30;48;2;255;217;47m##s\u001b[0m\n",
            "\u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m\"\u001b[0m \u001b[0;30;48;2;141;160;203m\"\u001b[0m \u001b[0;30;48;2;231;138;195m12\u001b[0m \u001b[0;30;48;2;166;216;84m.\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m*\u001b[0m \u001b[0;30;48;2;252;141;98m50\u001b[0m\n",
            "\u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m600\u001b[0m \u001b[0;30;48;2;166;216;84m[SEP]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30834ee6",
      "metadata": {
        "id": "30834ee6"
      },
      "source": [
        "**GPT-4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "ce63c289",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce63c289",
        "outputId": "0cd0b2da-84b7-4c19-b3ba-2895d10b8f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 100263\n",
            "\u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAPITAL\u001b[0m \u001b[0;30;48;2;166;216;84mIZATION\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m�\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m�\u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m �\u001b[0m \u001b[0;30;48;2;166;216;84m�\u001b[0m \u001b[0;30;48;2;255;217;47m�\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_tokens\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195m False\u001b[0m \u001b[0;30;48;2;166;216;84m None\u001b[0m \u001b[0;30;48;2;255;217;47m elif\u001b[0m \u001b[0;30;48;2;102;194;165m ==\u001b[0m \u001b[0;30;48;2;252;141;98m >=\u001b[0m \u001b[0;30;48;2;141;160;203m else\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m two\u001b[0m \u001b[0;30;48;2;255;217;47m tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\"\u001b[0m \u001b[0;30;48;2;252;141;98m   \u001b[0m \u001b[0;30;48;2;141;160;203m \"\u001b[0m \u001b[0;30;48;2;231;138;195m Three\u001b[0m \u001b[0;30;48;2;166;216;84m tabs\u001b[0m\n",
            "\u001b[0;30;48;2;255;217;47m:\u001b[0m \u001b[0;30;48;2;102;194;165m \"\u001b[0m \u001b[0;30;48;2;252;141;98m      \u001b[0m \u001b[0;30;48;2;141;160;203m \" \u001b[0m \u001b[0;30;48;2;231;138;195m12\u001b[0m \u001b[0;30;48;2;166;216;84m.\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m*\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m50\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m600\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"Xenova/gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01cc79c6",
      "metadata": {
        "id": "01cc79c6"
      },
      "source": [
        "**gpt2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "02f46eed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 30,
        "id": "02f46eed",
        "outputId": "a1a9eab9-b49c-4392-efbc-2c240e3d40ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 50257\n",
            "\u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAP\u001b[0m \u001b[0;30;48;2;166;216;84mITAL\u001b[0m \u001b[0;30;48;2;255;217;47mIZ\u001b[0m \u001b[0;30;48;2;102;194;165mATION\u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m�\u001b[0m \u001b[0;30;48;2;166;216;84m�\u001b[0m \u001b[0;30;48;2;255;217;47m �\u001b[0m \u001b[0;30;48;2;102;194;165m�\u001b[0m \u001b[0;30;48;2;252;141;98m�\u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195mshow\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m_\u001b[0m \u001b[0;30;48;2;255;217;47mt\u001b[0m \u001b[0;30;48;2;102;194;165mok\u001b[0m \u001b[0;30;48;2;252;141;98mens\u001b[0m \u001b[0;30;48;2;141;160;203m False\u001b[0m \u001b[0;30;48;2;231;138;195m None\u001b[0m \u001b[0;30;48;2;166;216;84m el\u001b[0m \u001b[0;30;48;2;255;217;47mif\u001b[0m\n",
            "\u001b[0;30;48;2;102;194;165m ==\u001b[0m \u001b[0;30;48;2;252;141;98m >=\u001b[0m \u001b[0;30;48;2;141;160;203m else\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m two\u001b[0m \u001b[0;30;48;2;255;217;47m tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\"\u001b[0m \u001b[0;30;48;2;252;141;98m\n",
            "\u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m \"\u001b[0m \u001b[0;30;48;2;255;217;47m Three\u001b[0m \u001b[0;30;48;2;102;194;165m tabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\u001b[0m \u001b[0;30;48;2;141;160;203m \"\u001b[0m \u001b[0;30;48;2;231;138;195m\n",
            "\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m12\u001b[0m\n",
            "\u001b[0;30;48;2;102;194;165m.\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m*\u001b[0m \u001b[0;30;48;2;231;138;195m50\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m \u001b[0;30;48;2;255;217;47m600\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803f47a9",
      "metadata": {
        "id": "803f47a9"
      },
      "source": [
        "**Flan-T5-small**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "3f5e5ded",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 30,
        "id": "3f5e5ded",
        "outputId": "86899b5f-1bd8-4f88-ed99-b309df5ad7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 32100\n",
            "\u001b[0;30;48;2;102;194;165mEnglish\u001b[0m \u001b[0;30;48;2;252;141;98mand\u001b[0m \u001b[0;30;48;2;141;160;203mCA\u001b[0m \u001b[0;30;48;2;231;138;195mPI\u001b[0m \u001b[0;30;48;2;166;216;84mTAL\u001b[0m \u001b[0;30;48;2;255;217;47mIZ\u001b[0m \u001b[0;30;48;2;102;194;165mATION\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m\u001b[0m \u001b[0;30;48;2;141;160;203m<unk>\u001b[0m \u001b[0;30;48;2;231;138;195m\u001b[0m \u001b[0;30;48;2;166;216;84m<unk>\u001b[0m \u001b[0;30;48;2;255;217;47mshow\u001b[0m \u001b[0;30;48;2;102;194;165m_\u001b[0m \u001b[0;30;48;2;252;141;98mto\u001b[0m \u001b[0;30;48;2;141;160;203mken\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195ms\u001b[0m \u001b[0;30;48;2;166;216;84mFal\u001b[0m \u001b[0;30;48;2;255;217;47ms\u001b[0m \u001b[0;30;48;2;102;194;165me\u001b[0m \u001b[0;30;48;2;252;141;98mNone\u001b[0m \u001b[0;30;48;2;141;160;203m\u001b[0m \u001b[0;30;48;2;231;138;195me\u001b[0m \u001b[0;30;48;2;166;216;84ml\u001b[0m\n",
            "\u001b[0;30;48;2;255;217;47mif\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98m=\u001b[0m \u001b[0;30;48;2;141;160;203m>\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84melse\u001b[0m \u001b[0;30;48;2;255;217;47m:\u001b[0m \u001b[0;30;48;2;102;194;165mtwo\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98mtab\u001b[0m \u001b[0;30;48;2;141;160;203ms\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165mThree\u001b[0m \u001b[0;30;48;2;252;141;98mtab\u001b[0m \u001b[0;30;48;2;141;160;203ms\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m\"\u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165m12.\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m*\u001b[0m \u001b[0;30;48;2;231;138;195m50\u001b[0m \u001b[0;30;48;2;166;216;84m=\u001b[0m\n",
            "\u001b[0;30;48;2;255;217;47m600\u001b[0m \u001b[0;30;48;2;102;194;165m\u001b[0m \u001b[0;30;48;2;252;141;98m</s>\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"google/flan-t5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22b96ac7",
      "metadata": {
        "id": "22b96ac7"
      },
      "source": [
        "**Starcoder 2 - 15B**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "a1463292",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 30,
        "id": "a1463292",
        "outputId": "20e7b7be-1fbc-44a1-dd30-ec542633aa64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 49152\n",
            "\u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAPITAL\u001b[0m \u001b[0;30;48;2;166;216;84mIZATION\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m�\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m�\u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m \u001b[0m \u001b[0;30;48;2;166;216;84m�\u001b[0m \u001b[0;30;48;2;255;217;47m�\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195mtokens\u001b[0m \u001b[0;30;48;2;166;216;84m False\u001b[0m \u001b[0;30;48;2;255;217;47m None\u001b[0m \u001b[0;30;48;2;102;194;165m elif\u001b[0m \u001b[0;30;48;2;252;141;98m ==\u001b[0m \u001b[0;30;48;2;141;160;203m >=\u001b[0m \u001b[0;30;48;2;231;138;195m else\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47m two\u001b[0m \u001b[0;30;48;2;102;194;165m tabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\"\u001b[0m \u001b[0;30;48;2;141;160;203m   \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m Three\u001b[0m \u001b[0;30;48;2;255;217;47m\n",
            "tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m \"\u001b[0m \u001b[0;30;48;2;141;160;203m      \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m1\u001b[0m \u001b[0;30;48;2;102;194;165m2\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m.\u001b[0m \u001b[0;30;48;2;141;160;203m0\u001b[0m \u001b[0;30;48;2;231;138;195m*\u001b[0m \u001b[0;30;48;2;166;216;84m5\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m=\u001b[0m \u001b[0;30;48;2;252;141;98m6\u001b[0m \u001b[0;30;48;2;141;160;203m0\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195m0\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"bigcode/starcoder2-15b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a35ea3",
      "metadata": {
        "id": "27a35ea3"
      },
      "source": [
        "**Phi-3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "23682435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 45,
        "id": "23682435",
        "outputId": "24c28595-59fe-4335-da01-9960d1e703e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 32011\n",
            "\u001b[0;30;48;2;102;194;165m\u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203mEnglish\u001b[0m \u001b[0;30;48;2;231;138;195mand\u001b[0m \u001b[0;30;48;2;166;216;84mC\u001b[0m \u001b[0;30;48;2;255;217;47mAP\u001b[0m \u001b[0;30;48;2;102;194;165mIT\u001b[0m \u001b[0;30;48;2;252;141;98mAL\u001b[0m\n",
            "\u001b[0;30;48;2;141;160;203mIZ\u001b[0m \u001b[0;30;48;2;231;138;195mATION\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m�\u001b[0m \u001b[0;30;48;2;102;194;165m�\u001b[0m \u001b[0;30;48;2;252;141;98m�\u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m�\u001b[0m \u001b[0;30;48;2;255;217;47m�\u001b[0m \u001b[0;30;48;2;102;194;165m�\u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203mshow\u001b[0m \u001b[0;30;48;2;231;138;195m_\u001b[0m \u001b[0;30;48;2;166;216;84mto\u001b[0m \u001b[0;30;48;2;255;217;47mkens\u001b[0m\n",
            "\u001b[0;30;48;2;102;194;165mFalse\u001b[0m \u001b[0;30;48;2;252;141;98mNone\u001b[0m \u001b[0;30;48;2;141;160;203melif\u001b[0m \u001b[0;30;48;2;231;138;195m==\u001b[0m \u001b[0;30;48;2;166;216;84m>=\u001b[0m \u001b[0;30;48;2;255;217;47melse\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98mtwo\u001b[0m \u001b[0;30;48;2;141;160;203mtabs\u001b[0m \u001b[0;30;48;2;231;138;195m:\"\u001b[0m \u001b[0;30;48;2;166;216;84m  \u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165mThree\u001b[0m \u001b[0;30;48;2;252;141;98mtabs\u001b[0m \u001b[0;30;48;2;141;160;203m:\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195m\"\u001b[0m \u001b[0;30;48;2;166;216;84m     \u001b[0m \u001b[0;30;48;2;255;217;47m\"\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98m1\u001b[0m \u001b[0;30;48;2;141;160;203m2\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m0\u001b[0m\n",
            "\u001b[0;30;48;2;255;217;47m*\u001b[0m \u001b[0;30;48;2;102;194;165m5\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m \u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m6\u001b[0m \u001b[0;30;48;2;166;216;84m0\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeepSeek"
      ],
      "metadata": {
        "id": "xbqUeik3STz6"
      },
      "id": "xbqUeik3STz6"
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"deepseek-ai/DeepSeek-R1\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G98fmKvR0dQ",
        "outputId": "31a4ef75-4bf5-412b-f178-dd0530447d3c"
      },
      "id": "0G98fmKvR0dQ",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 128815\n",
            "\u001b[0;30;48;2;102;194;165m<｜begin▁of▁sentence｜>\u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203mEnglish\u001b[0m \u001b[0;30;48;2;231;138;195m and\u001b[0m \u001b[0;30;48;2;166;216;84m CAP\u001b[0m \u001b[0;30;48;2;255;217;47mITAL\u001b[0m \u001b[0;30;48;2;102;194;165mIZATION\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m�\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m鸟\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_t\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195mokens\u001b[0m \u001b[0;30;48;2;166;216;84m False\u001b[0m \u001b[0;30;48;2;255;217;47m None\u001b[0m \u001b[0;30;48;2;102;194;165m elif\u001b[0m \u001b[0;30;48;2;252;141;98m ==\u001b[0m \u001b[0;30;48;2;141;160;203m >=\u001b[0m \u001b[0;30;48;2;231;138;195m else\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47m two\u001b[0m \u001b[0;30;48;2;102;194;165m tabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\"\u001b[0m \u001b[0;30;48;2;141;160;203m   \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m Three\u001b[0m \u001b[0;30;48;2;255;217;47m\n",
            "tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m \"\u001b[0m \u001b[0;30;48;2;141;160;203m      \u001b[0m \u001b[0;30;48;2;231;138;195m \" \u001b[0m \u001b[0;30;48;2;166;216;84m12\u001b[0m \u001b[0;30;48;2;255;217;47m.\u001b[0m \u001b[0;30;48;2;102;194;165m0\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m*\u001b[0m \u001b[0;30;48;2;141;160;203m50\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84m600\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"deepseek-ai/DeepSeek-V3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGZo-zzJS9lL",
        "outputId": "855a1f98-914a-49da-ae9c-b84f6cd0c4ce"
      },
      "id": "sGZo-zzJS9lL",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 128815\n",
            "\u001b[0;30;48;2;102;194;165m<｜begin▁of▁sentence｜>\u001b[0m \u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203mEnglish\u001b[0m \u001b[0;30;48;2;231;138;195m and\u001b[0m \u001b[0;30;48;2;166;216;84m CAP\u001b[0m \u001b[0;30;48;2;255;217;47mITAL\u001b[0m \u001b[0;30;48;2;102;194;165mIZATION\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m \u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m�\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47m鸟\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mshow\u001b[0m \u001b[0;30;48;2;141;160;203m_t\u001b[0m\n",
            "\u001b[0;30;48;2;231;138;195mokens\u001b[0m \u001b[0;30;48;2;166;216;84m False\u001b[0m \u001b[0;30;48;2;255;217;47m None\u001b[0m \u001b[0;30;48;2;102;194;165m elif\u001b[0m \u001b[0;30;48;2;252;141;98m ==\u001b[0m \u001b[0;30;48;2;141;160;203m >=\u001b[0m \u001b[0;30;48;2;231;138;195m else\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m:\u001b[0m \u001b[0;30;48;2;255;217;47m two\u001b[0m \u001b[0;30;48;2;102;194;165m tabs\u001b[0m \u001b[0;30;48;2;252;141;98m:\"\u001b[0m \u001b[0;30;48;2;141;160;203m   \u001b[0m \u001b[0;30;48;2;231;138;195m \"\u001b[0m \u001b[0;30;48;2;166;216;84m Three\u001b[0m \u001b[0;30;48;2;255;217;47m\n",
            "tabs\u001b[0m \u001b[0;30;48;2;102;194;165m:\u001b[0m \u001b[0;30;48;2;252;141;98m \"\u001b[0m \u001b[0;30;48;2;141;160;203m      \u001b[0m \u001b[0;30;48;2;231;138;195m \" \u001b[0m \u001b[0;30;48;2;166;216;84m12\u001b[0m \u001b[0;30;48;2;255;217;47m.\u001b[0m \u001b[0;30;48;2;102;194;165m0\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m*\u001b[0m \u001b[0;30;48;2;141;160;203m50\u001b[0m \u001b[0;30;48;2;231;138;195m=\u001b[0m \u001b[0;30;48;2;166;216;84m600\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLama"
      ],
      "metadata": {
        "id": "NfLjXDerTnjE"
      },
      "id": "NfLjXDerTnjE"
    },
    {
      "cell_type": "markdown",
      "id": "47a7ad46",
      "metadata": {
        "id": "47a7ad46"
      },
      "source": [
        "**Qwen2 - Vision-Language Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "637e9107",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "637e9107",
        "outputId": "36e6bfa3-395a-478b-93af-28c02431373d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 151665\n",
            "\u001b[0;30;48;2;102;194;165m \u001b[0m \u001b[0;30;48;2;252;141;98mEnglish\u001b[0m \u001b[0;30;48;2;141;160;203m and\u001b[0m \u001b[0;30;48;2;231;138;195m CAPITAL\u001b[0m \u001b[0;30;48;2;166;216;84mIZATION\u001b[0m \u001b[0;30;48;2;255;217;47m \u001b[0m \u001b[0;30;48;2;102;194;165m🎵\u001b[0m\n",
            "\u001b[0;30;48;2;252;141;98m �\u001b[0m \u001b[0;30;48;2;141;160;203m�\u001b[0m \u001b[0;30;48;2;231;138;195m�\u001b[0m \u001b[0;30;48;2;166;216;84m \u001b[0m \u001b[0;30;48;2;255;217;47mshow\u001b[0m \u001b[0;30;48;2;102;194;165m_tokens\u001b[0m \u001b[0;30;48;2;252;141;98m False\u001b[0m \u001b[0;30;48;2;141;160;203m\n",
            "None\u001b[0m \u001b[0;30;48;2;231;138;195m elif\u001b[0m \u001b[0;30;48;2;166;216;84m ==\u001b[0m \u001b[0;30;48;2;255;217;47m >=\u001b[0m \u001b[0;30;48;2;102;194;165m else\u001b[0m \u001b[0;30;48;2;252;141;98m:\u001b[0m \u001b[0;30;48;2;141;160;203m two\u001b[0m \u001b[0;30;48;2;231;138;195m tabs\u001b[0m\n",
            "\u001b[0;30;48;2;166;216;84m:\"\u001b[0m \u001b[0;30;48;2;255;217;47m   \u001b[0m \u001b[0;30;48;2;102;194;165m \"\u001b[0m \u001b[0;30;48;2;252;141;98m Three\u001b[0m \u001b[0;30;48;2;141;160;203m tabs\u001b[0m \u001b[0;30;48;2;231;138;195m:\u001b[0m \u001b[0;30;48;2;166;216;84m \"\u001b[0m \u001b[0;30;48;2;255;217;47m\n",
            "\u001b[0m \u001b[0;30;48;2;102;194;165m \" \u001b[0m \u001b[0;30;48;2;252;141;98m1\u001b[0m \u001b[0;30;48;2;141;160;203m2\u001b[0m \u001b[0;30;48;2;231;138;195m.\u001b[0m \u001b[0;30;48;2;166;216;84m0\u001b[0m \u001b[0;30;48;2;255;217;47m*\u001b[0m \u001b[0;30;48;2;102;194;165m5\u001b[0m \u001b[0;30;48;2;252;141;98m0\u001b[0m\n",
            "\u001b[0;30;48;2;141;160;203m=\u001b[0m \u001b[0;30;48;2;231;138;195m6\u001b[0m \u001b[0;30;48;2;166;216;84m0\u001b[0m \u001b[0;30;48;2;255;217;47m0\u001b[0m \u001b[0;30;48;2;102;194;165m \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "show_tokens(text, \"Qwen/Qwen2.5-VL-7B-Instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42ba1b5c",
      "metadata": {
        "id": "42ba1b5c"
      },
      "source": [
        "## you will reinforce your understanding of the transformer architecture by exploring the decoder-only [model](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) `microsoft/Phi-3-mini-4k-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee90eb06",
      "metadata": {
        "id": "ee90eb06"
      },
      "source": [
        "## Loading the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "d2b1b173",
      "metadata": {
        "height": 62,
        "id": "d2b1b173"
      },
      "outputs": [],
      "source": [
        "# import the required classes\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7058ac69",
      "metadata": {
        "id": "7058ac69"
      },
      "source": [
        "**Understanding Tokenization in Language Models**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770e7ab8",
      "metadata": {
        "id": "770e7ab8"
      },
      "source": [
        "Now you can wrap the model and the tokenizer in a [pipeline](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.pipeline) object that has \"text-generation\" as task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54cf1d2c",
      "metadata": {
        "id": "54cf1d2c"
      },
      "source": [
        "## Generating a Text Response to a Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "c6e193ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 113,
        "id": "c6e193ec",
        "outputId": "616d27e4-d7b7-4b15-f6ee-e7337be710b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.  The email is just one of many. If a customer wanted to take part in my gardening show on Sunday, that is how I would present it to him and he would be able to use my services and experience as a gift. Thank you SO\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened. \"\n",
        "\n",
        "output = generator(prompt)\n",
        "\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27336f2c",
      "metadata": {
        "id": "27336f2c"
      },
      "source": [
        "## Exploring the Model's Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc30078",
      "metadata": {
        "id": "5fc30078"
      },
      "source": [
        "You can print the model to take a look at its architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1955ead",
      "metadata": {
        "id": "c1955ead"
      },
      "source": [
        "**Loading or Evaluating a Machine Learning Model**\n",
        "\n",
        "This part of the code involves interacting with a trained model, such as loading, fine-tuning, or making predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "53876cd6",
      "metadata": {
        "height": 30,
        "id": "53876cd6"
      },
      "outputs": [],
      "source": [
        "#model.model.embed_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af0c1fbf",
      "metadata": {
        "id": "af0c1fbf"
      },
      "source": [
        "**Loading or Evaluating a Machine Learning Model**\n",
        "\n",
        "This part of the code involves interacting with a trained model, such as loading, fine-tuning, or making predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "83b640c4",
      "metadata": {
        "height": 30,
        "id": "83b640c4"
      },
      "outputs": [],
      "source": [
        "#model.model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672b6044",
      "metadata": {
        "id": "672b6044"
      },
      "source": [
        "There are 32 transformer blocks or layers. You can access any particular block."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def54983",
      "metadata": {
        "id": "def54983"
      },
      "source": [
        "**Loading or Evaluating a Machine Learning Model**\n",
        "\n",
        "This part of the code involves interacting with a trained model, such as loading, fine-tuning, or making predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "e1e86c8c",
      "metadata": {
        "height": 30,
        "id": "e1e86c8c"
      },
      "outputs": [],
      "source": [
        "#model.model.layers[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d1cfaf",
      "metadata": {
        "id": "15d1cfaf"
      },
      "source": [
        "## Generating a Single Token to a Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "7694bbda",
      "metadata": {
        "height": 30,
        "id": "7694bbda"
      },
      "outputs": [],
      "source": [
        "prompt = \"The capital of Canada is\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "467c6ff2",
      "metadata": {
        "id": "467c6ff2"
      },
      "source": [
        "You'll need first to tokenize the prompt and get the ids of the tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c2f995b",
      "metadata": {
        "id": "3c2f995b"
      },
      "source": [
        "**Understanding Tokenization in Language Models**\n",
        "\n",
        "This section demonstrates how different tokenizers process text, showing how tokenization impacts model efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "ae5dfe1c",
      "metadata": {
        "height": 79,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae5dfe1c",
        "outputId": "ea2d8dab-2015-4665-cc74-62aabc9c42f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 450, 7483,  310, 7400,  338]])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe988d6c",
      "metadata": {
        "id": "fe988d6c"
      },
      "source": [
        "Let's now pass the token ids to the transformer block (before the LM head)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "gCI8RZ6uTKgn"
      },
      "id": "gCI8RZ6uTKgn",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "d48d9491",
      "metadata": {
        "height": 62,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9e07898b63554cf6977cf91730e041a4",
            "bd32d132e9a646ecb45f00c45cb57b5f",
            "8936a832f4a74d5f926ab75111eed595",
            "963c75e350d347c4b6c199a73305efd3",
            "66a030be84984fb7a8b6f93be653e31f",
            "f59d086ee5cb4faf9b45ddc6789ee421",
            "ac0cf8683841416e95629e1759ead1a4",
            "4061e8a2a26e487e8baf8ab86fe3be4d",
            "2fb752bbd38f43e58f93868436af53b8",
            "7314ee887a254293b0643e5a9aacce77",
            "3786608589114761b2de3581ca566488"
          ]
        },
        "id": "d48d9491",
        "outputId": "98641331-1f6f-47e6-d5e1-015794583c53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e07898b63554cf6977cf91730e041a4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "device = torch.device( \"cpu\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=device, # or device_map=device, if you defined device\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ").to(device)  # Explicitly move the model to the device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = model.model(input_ids.to(device))  # Perform the forward pass\n"
      ],
      "metadata": {
        "id": "ZBHZ0aRNTlgU"
      },
      "id": "ZBHZ0aRNTlgU",
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "db13d318",
      "metadata": {
        "id": "db13d318"
      },
      "source": [
        "The transformer block outputs for each token a vector of size 3072 (embedding size). Let's check the shape of this output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "f0e3eab6",
      "metadata": {
        "height": 62,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e3eab6",
        "outputId": "b67bc2f0-661b-4e29-933b-d2079396037f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 3072])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "# Get the shape the output the model before the lm_head\n",
        "model_output[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "2a18af1e",
      "metadata": {
        "height": 62,
        "id": "2a18af1e"
      },
      "outputs": [],
      "source": [
        "# Get the output of the lm_head\n",
        "lm_head_output = model.lm_head(model_output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "4c02ed1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 30,
        "id": "4c02ed1d",
        "outputId": "756fd295-0640-4384-d9f8-284c2a64547c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32064])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "lm_head_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "0bf01fbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "height": 47,
        "id": "0bf01fbf",
        "outputId": "e24d84af-87c9-4112-8550-e6104b2c21a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13476)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "token_id = lm_head_output[0,-1].argmax(-1)\n",
        "token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83117cbe",
      "metadata": {
        "id": "83117cbe"
      },
      "source": [
        "Finally, let's decode the returned token id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "169f283f",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "169f283f",
        "outputId": "8af74fb2-d58f-4997-c338-be31f0d097a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ott'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "tokenizer.decode(token_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "vreHYGWgTuvZ"
      },
      "id": "vreHYGWgTuvZ",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.model.embed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCsqWH77Vwzb",
        "outputId": "db6a5cf8-990b-4ac7-994e-afa2678e97e5"
      },
      "id": "TCsqWH77Vwzb",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32064, 3072, padding_idx=32000)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.model.base_model"
      ],
      "metadata": {
        "id": "bLMYTnLKV0bA"
      },
      "id": "bLMYTnLKV0bA",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "eTvyo3diXIS9"
      },
      "id": "eTvyo3diXIS9"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "\n",
        "# Device Selection\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IqGS0LDeWJo0"
      },
      "id": "IqGS0LDeWJo0",
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"hf-tiny-model-private/tiny-random-AlbertForSequenceClassification\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"hf-tiny-model-private/tiny-random-AlbertForSequenceClassification\")"
      ],
      "metadata": {
        "id": "33hncSlKXNt5"
      },
      "id": "33hncSlKXNt5",
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate reviews and classifying them"
      ],
      "metadata": {
        "id": "09KnGVryl8Ro"
      },
      "id": "09KnGVryl8Ro"
    },
    {
      "cell_type": "code",
      "source": [
        "iphone_16_pro_reviews = [\n",
        "    \"The iPhone 16 Pro's camera quality is mind-blowing, especially in low light!\",\n",
        "    \"Battery life is impressive, but the phone feels slightly heavier than expected.\",\n",
        "    \"I love the new design and display, but the price is quite steep.\",\n",
        "    \"Face ID is faster than ever, making unlocking the phone seamless.\",\n",
        "    \"The new A18 chip delivers unmatched performance for gaming and multitasking.\",\n",
        "    \"I'm amazed by the build quality, but I wish the charging speed was faster.\",\n",
        "    \"The dynamic island feature is intuitive and genuinely enhances the user experience.\",\n",
        "    \"Although the camera is outstanding, I expected more innovation in other features.\",\n",
        "    \"The phone's integration with the Apple ecosystem is seamless and worth every penny.\",\n",
        "    \"I appreciate the eco-friendly packaging, but I miss having a charging brick included.\",\n",
        "    \"The 120Hz ProMotion display is buttery smooth and a joy to use daily.\",\n",
        "    \"It's the perfect phone for content creators with its advanced video recording features.\",\n",
        "    \"While the new titanium finish is sleek, it feels slippery without a case.\",\n",
        "    \"The 5G connectivity is super fast, but it drains the battery quicker than I expected.\",\n",
        "    \"The sound quality on the speakers is phenomenal for watching movies and listening to music.\",\n",
        "    \"The storage options are fantastic, though the higher tiers are a bit overpriced.\",\n",
        "    \"It's great to see Apple's commitment to sustainability with the new materials used.\",\n",
        "    \"This phone has truly redefined what a flagship smartphone should be.\",\n",
        "    \"The new color options are stunning and a great way to stand out from the crowd.\",\n",
        "    \"I love how durable the phone feels, but I wish it came with more color choices.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "ELC-_ywZrHEP"
      },
      "id": "ELC-_ywZrHEP",
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
        "\n",
        "# Load models for sentiment analysis and text generation\n",
        "model_name_sentiment = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer_sentiment = AutoTokenizer.from_pretrained(model_name_sentiment)\n",
        "model_sentiment = AutoModelForSequenceClassification.from_pretrained(model_name_sentiment).to('cpu')\n",
        "\n",
        "model_name_generation = \"gpt2\"  # Using gpt2 for text generation\n",
        "tokenizer_generation = AutoTokenizer.from_pretrained(model_name_generation)\n",
        "model_generation = AutoModelForCausalLM.from_pretrained(model_name_generation).to('cpu')\n",
        "\n",
        "# Sentiment Classification Pipeline\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model_sentiment,\n",
        "    tokenizer=tokenizer_sentiment,\n",
        "    device=-1  # Run on the CPU\n",
        ")\n",
        "\n",
        "# Text Generation Pipeline\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_generation,\n",
        "    tokenizer=tokenizer_generation,\n",
        "    device=-1,  # Run on the CPU\n",
        "    max_new_tokens=50,  # Limit generated text length\n",
        "    num_return_sequences=1  # Generate only one sequence per prompt\n",
        ")\n",
        "\n",
        "\n",
        "# Classify Sentiment of Each Comment\n",
        "for comment in iphone_16_pro_reviews:\n",
        "   # print(\"Comment:\", comment)\n",
        "    result = classifier(comment)[0]\n",
        "    sentiment = result['label']\n",
        "    print(comment , \":\", sentiment)\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X38IIP4xmBDk",
        "outputId": "4b74932e-37b4-4b8a-cb43-53c03c61efe1"
      },
      "id": "X38IIP4xmBDk",
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iPhone 16 Pro's camera quality is mind-blowing, especially in low light! : POSITIVE\n",
            "--------------------\n",
            "Battery life is impressive, but the phone feels slightly heavier than expected. : NEGATIVE\n",
            "--------------------\n",
            "I love the new design and display, but the price is quite steep. : NEGATIVE\n",
            "--------------------\n",
            "Face ID is faster than ever, making unlocking the phone seamless. : POSITIVE\n",
            "--------------------\n",
            "The new A18 chip delivers unmatched performance for gaming and multitasking. : POSITIVE\n",
            "--------------------\n",
            "I'm amazed by the build quality, but I wish the charging speed was faster. : NEGATIVE\n",
            "--------------------\n",
            "The dynamic island feature is intuitive and genuinely enhances the user experience. : POSITIVE\n",
            "--------------------\n",
            "Although the camera is outstanding, I expected more innovation in other features. : NEGATIVE\n",
            "--------------------\n",
            "The phone's integration with the Apple ecosystem is seamless and worth every penny. : POSITIVE\n",
            "--------------------\n",
            "I appreciate the eco-friendly packaging, but I miss having a charging brick included. : NEGATIVE\n",
            "--------------------\n",
            "The 120Hz ProMotion display is buttery smooth and a joy to use daily. : POSITIVE\n",
            "--------------------\n",
            "It's the perfect phone for content creators with its advanced video recording features. : POSITIVE\n",
            "--------------------\n",
            "While the new titanium finish is sleek, it feels slippery without a case. : NEGATIVE\n",
            "--------------------\n",
            "The 5G connectivity is super fast, but it drains the battery quicker than I expected. : NEGATIVE\n",
            "--------------------\n",
            "The sound quality on the speakers is phenomenal for watching movies and listening to music. : POSITIVE\n",
            "--------------------\n",
            "The storage options are fantastic, though the higher tiers are a bit overpriced. : POSITIVE\n",
            "--------------------\n",
            "It's great to see Apple's commitment to sustainability with the new materials used. : POSITIVE\n",
            "--------------------\n",
            "This phone has truly redefined what a flagship smartphone should be. : POSITIVE\n",
            "--------------------\n",
            "The new color options are stunning and a great way to stand out from the crowd. : POSITIVE\n",
            "--------------------\n",
            "I love how durable the phone feels, but I wish it came with more color choices. : NEGATIVE\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtGF6aDsrM7_"
      },
      "id": "AtGF6aDsrM7_",
      "execution_count": 168,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e07898b63554cf6977cf91730e041a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd32d132e9a646ecb45f00c45cb57b5f",
              "IPY_MODEL_8936a832f4a74d5f926ab75111eed595",
              "IPY_MODEL_963c75e350d347c4b6c199a73305efd3"
            ],
            "layout": "IPY_MODEL_66a030be84984fb7a8b6f93be653e31f"
          }
        },
        "bd32d132e9a646ecb45f00c45cb57b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59d086ee5cb4faf9b45ddc6789ee421",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0cf8683841416e95629e1759ead1a4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8936a832f4a74d5f926ab75111eed595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4061e8a2a26e487e8baf8ab86fe3be4d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fb752bbd38f43e58f93868436af53b8",
            "value": 2
          }
        },
        "963c75e350d347c4b6c199a73305efd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7314ee887a254293b0643e5a9aacce77",
            "placeholder": "​",
            "style": "IPY_MODEL_3786608589114761b2de3581ca566488",
            "value": " 2/2 [00:00&lt;00:00,  2.60it/s]"
          }
        },
        "66a030be84984fb7a8b6f93be653e31f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59d086ee5cb4faf9b45ddc6789ee421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0cf8683841416e95629e1759ead1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4061e8a2a26e487e8baf8ab86fe3be4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb752bbd38f43e58f93868436af53b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7314ee887a254293b0643e5a9aacce77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3786608589114761b2de3581ca566488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}