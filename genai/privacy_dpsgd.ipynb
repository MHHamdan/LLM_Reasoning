{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwDK47gfLsYf"
   },
   "source": [
    "# Implement Differential Privacy with TensorFlow Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Learn how to wrap existing optimizers (e.g., SGD, Adam) into their differentially private counterparts using TensorFlow Privacy\n",
    "* Understand hyperparameters introduced by differentially private machine learning\n",
    "* Measure the privacy guarantee provided using analysis tools included in TensorFlow Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00fQV7e0Unz3"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsCUvXP0W4j2"
   },
   "source": [
    "[Differential privacy](https://en.wikipedia.org/wiki/Differential_privacy) (DP) is a framework for measuring the privacy guarantees provided by an algorithm. Through the lens of differential privacy, you can design machine learning algorithms that responsibly train models on private data. Learning with differential privacy provides measurable guarantees of privacy, helping to mitigate the risk of exposing sensitive training data in machine learning. Intuitively, a model trained with differential privacy should not be affected by any single training example, or small set of training examples, in its data set. This helps mitigate the risk of exposing sensitive training data in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vd8qUwEW5pP"
   },
   "source": [
    "The basic idea of this approach, called differentially private stochastic gradient descent (DP-SGD), is to modify the gradients\n",
    "used in stochastic gradient descent (SGD), which lies at the core of almost all deep learning algorithms. Models trained with DP-SGD provide provable differential privacy guarantees for their input data. There are two modifications made to the vanilla SGD algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUphKzYu01O9"
   },
   "source": [
    "1. First, the sensitivity of each gradient needs to be bounded. In other words, you need to limit how much each individual training point sampled in a minibatch can influence gradient computations and the resulting updates applied to model parameters. This can be done by *clipping* each gradient computed on each training point.\n",
    "2. *Random noise* is sampled and added to the clipped gradients to make it statistically impossible to know whether or not a particular data point was included in the training dataset by comparing the updates SGD applies when it operates with or without this particular data point in the training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXU7MZhhW-aL"
   },
   "source": [
    "This tutorial uses [tf.keras](https://www.tensorflow.org/guide/keras) to train a convolutional neural network (CNN) to recognize handwritten digits with the DP-SGD optimizer provided by the TensorFlow Privacy library. TensorFlow Privacy provides code that wraps an existing TensorFlow optimizer to create a variant that implements DP-SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijJYKVc05DYX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r56BqqyEqA16",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-privacy==0.8.12 in /home/jupyter/.local/lib/python3.10/site-packages (0.8.12)\n",
      "Requirement already satisfied: dp_accounting==0.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --no-deps tensorflow-privacy==0.8.12 dp_accounting==0.4.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKuHPYQCsV-x"
   },
   "source": [
    "Begin by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ef56gCUqrdVn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_fVhfUyeI3d"
   },
   "source": [
    "Import TensorFlow Privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU1p8N7M5Mmn"
   },
   "source": [
    "## Load and pre-process the dataset\n",
    "\n",
    "Load the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_1ML23FlueTr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_data, train_labels = train\n",
    "test_data, test_labels = test\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n",
    "test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
    "\n",
    "train_labels = np.array(train_labels, dtype=np.int32)\n",
    "test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "assert train_data.min() == 0.0\n",
    "assert train_data.max() == 1.0\n",
    "assert test_data.min() == 0.0\n",
    "assert test_data.max() == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVDcswOCtlr3"
   },
   "source": [
    "## Define the hyperparameters\n",
    "Set learning model hyperparamter values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXNp_25y7JP2"
   },
   "source": [
    "DP-SGD has three general hyperamater and three privacy-specific hyperparameters that you must tune:\n",
    "\n",
    "**General hyperparameters**\n",
    "\n",
    "1. `epochs` (int) - This refers to the one entire passing of training data through the algorithm. Larger epoch increase the privacy risks since the model is trained on a same data point for multiple times.\n",
    "2. `batch_size` (int) - Batch size affects different aspects of DP-SGD training. For instance, increasing the batch size could reduce the amount of noise added during training under the same privacy guarantee, which reduces the training variance.\n",
    "3. `learning_rate` (float) - This hyperparameter already exists in vanilla SGD. The higher the learning rate, the more each update matters. If the updates are noisy (such as when the additive noise is large compared to the clipping threshold), a low learning rate may help the training procedure converge. \n",
    "\n",
    "**Privacy-specific hyperparameters**\n",
    "1. `l2_norm_clip` (float) - The maximum Euclidean (L2) norm of each gradient that is applied to update model parameters. This hyperparameter is used to bound the optimizer's sensitivity to individual training points. \n",
    "2. `noise_multiplier` (float) - Ratio of the standard deviation to the clipping norm (The amount of noise sampled and added to gradients during training). Generally, more noise results in better privacy (often, but not necessarily, at the expense of lower utility).\n",
    "3.   `microbatches` (int) - Each batch of data is split in smaller units called microbatches. By default, each microbatch should contain a single training example. This allows us to clip gradients on a per-example basis rather than after they have been averaged across the minibatch. This in turn decreases the (negative) effect of clipping on signal found in the gradient and typically maximizes utility. However, computational overhead can be reduced by increasing the size of microbatches to include more than one training examples. The average gradient across these multiple training examples is then clipped. The total number of examples consumed in a batch, i.e., one step of gradient descent, remains the same. The number of microbatches should evenly divide the batch size. \n",
    "\n",
    "\n",
    "Use the hyperparameter values below to obtain a reasonably accurate model (95% test accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pVw_r2Mq7ntd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.25\n",
    "\n",
    "l2_norm_clip = 1.0\n",
    "noise_multiplier = 0.5\n",
    "num_microbatches = 32  # Same as the batch size (i.e. no microbatch)\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "    raise ValueError(\n",
    "        \"Batch noise_multipliere should be an integer multiple of the number of microbatches\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXAmHcNOmHc5"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Define a convolutional neural network as the learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oCOo8aOLmFta",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-01-18 16:32:13.302735: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            16,\n",
    "            8,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            input_shape=(28, 28, 1),\n",
    "        ),\n",
    "        tf.keras.layers.MaxPool2D(2, 1),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, 4, strides=2, padding=\"valid\", activation=\"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.MaxPool2D(2, 1),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_privacy in /home/jupyter/.local/lib/python3.10/site-packages (0.8.12)\n",
      "Requirement already satisfied: absl-py==1.*,>=1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (1.4.0)\n",
      "Requirement already satisfied: attrs>=21.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (24.3.0)\n",
      "Requirement already satisfied: dm-tree==0.1.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (0.1.8)\n",
      "Requirement already satisfied: dp-accounting==0.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow_privacy) (0.4.3)\n",
      "Collecting immutabledict~=2.2 (from tensorflow_privacy)\n",
      "  Downloading immutabledict-2.2.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: matplotlib~=3.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (3.9.4)\n",
      "Collecting numpy~=1.21 (from tensorflow_privacy)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting packaging~=22.0 (from tensorflow_privacy)\n",
      "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting pandas~=1.4 (from tensorflow_privacy)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (1.6.0)\n",
      "Requirement already satisfied: scipy~=1.9 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (1.13.1)\n",
      "Requirement already satisfied: statsmodels~=0.13 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (0.14.4)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow_privacy) (2.11.0)\n",
      "Collecting tensorflow-probability~=0.22.0 (from tensorflow_privacy)\n",
      "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tensorflow~=2.4 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow_privacy) (2.18.0)\n",
      "Collecting tf-models-official~=2.13 (from tensorflow_privacy)\n",
      "  Downloading tf_models_official-2.18.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mpmath~=1.2 (from dp-accounting==0.4.3->tensorflow_privacy)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn==1.*,>=1.0->tensorflow_privacy) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn==1.*,>=1.0->tensorflow_privacy) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from matplotlib~=3.3->tensorflow_privacy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pandas~=1.4->tensorflow_privacy) (2024.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from statsmodels~=0.13->tensorflow_privacy) (1.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow~=2.4->tensorflow_privacy) (0.29.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-probability~=0.22.0->tensorflow_privacy) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-probability~=0.22.0->tensorflow_privacy) (2.2.1)\n",
      "Requirement already satisfied: Cython in /home/jupyter/.local/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (0.29.37)\n",
      "Collecting ai-edge-litert>=1.0.1 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading ai_edge_litert-1.0.1-cp310-cp310-manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting gin-config (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (1.8.0)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: oauth2client in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (4.1.3)\n",
      "Collecting opencv-python-headless (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (5.9.3)\n",
      "Collecting py-cpuinfo>=3.3.0 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pycocotools (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (6.0.2)\n",
      "Collecting sacrebleu (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting sentencepiece (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting seqeval (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (4.9.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tf-models-official~=2.13->tensorflow_privacy) (0.16.1)\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "Collecting tensorflow-text~=2.18.0 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting tf-keras>=2.16.0 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tf-slim>=1.1.0 (from tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow_privacy) (0.45.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (0.21.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (2.37.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (0.1.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (1.34.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy) (2024.12.14)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy) (4.67.1)\n",
      "Collecting python-slugify (from kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy) (1.26.20)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy) (6.2.0)\n",
      "Requirement already satisfied: rich in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow~=2.4->tensorflow_privacy) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow~=2.4->tensorflow_privacy) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow~=2.4->tensorflow_privacy) (0.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow~=2.4->tensorflow_privacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow~=2.4->tensorflow_privacy) (3.10)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.4->tensorflow_privacy) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.4->tensorflow_privacy) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.4->tensorflow_privacy) (3.1.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from oauth2client->tf-models-official~=2.13->tensorflow_privacy) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from oauth2client->tf-models-official~=2.13->tensorflow_privacy) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from oauth2client->tf-models-official~=2.13->tensorflow_privacy) (4.9)\n",
      "Collecting portalocker (from sacrebleu->tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from sacrebleu->tf-models-official~=2.13->tensorflow_privacy) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from sacrebleu->tf-models-official~=2.13->tensorflow_privacy) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from sacrebleu->tf-models-official~=2.13->tensorflow_privacy) (0.4.6)\n",
      "Collecting lxml (from sacrebleu->tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: array-record in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (0.6.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (8.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (1.11.0)\n",
      "Requirement already satisfied: promise in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (0.14.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (0.10.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (2024.12.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (6.4.5)\n",
      "Requirement already satisfied: zipp in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official~=2.13->tensorflow_privacy) (3.21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (1.63.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow~=2.4->tensorflow_privacy)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official~=2.13->tensorflow_privacy) (4.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow~=2.4->tensorflow_privacy) (3.0.2)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle>=1.3.9->tf-models-official~=2.13->tensorflow_privacy)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow~=2.4->tensorflow_privacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow~=2.4->tensorflow_privacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow~=2.4->tensorflow_privacy) (0.1.2)\n",
      "Downloading immutabledict-2.2.5-py3-none-any.whl (4.1 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n",
      "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tf_models_official-2.18.0-py2.py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ai_edge_litert-1.0.1-cp310-cp310-manylinux_2_17_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
      "Downloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: kaggle, seqeval\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=2b083621079bf3a924302f95e42d5f40f69b9a0b722644e34b29962a93ab83f8\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=51124541a87913e0d3e6b06465c0ac3ca367aec05c0c3929d4029cb103a81cac\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built kaggle seqeval\n",
      "Installing collected packages: text-unidecode, sentencepiece, py-cpuinfo, mpmath, gin-config, tf-slim, python-slugify, protobuf, portalocker, packaging, numpy, lxml, immutabledict, tensorflow-probability, tensorflow-model-optimization, sacrebleu, pandas, opencv-python-headless, kaggle, ai-edge-litert, seqeval, pycocotools, tf-keras, tensorflow-text, tf-models-official\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.25.0\n",
      "    Uninstalling tensorflow-probability-0.25.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.25.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: tf-keras\n",
      "    Found existing installation: tf-keras 2.15.0\n",
      "    Uninstalling tf-keras-2.15.0:\n",
      "      Successfully uninstalled tf-keras-2.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "visions 0.7.6 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ai-edge-litert-1.0.1 gin-config-0.5.0 immutabledict-2.2.5 kaggle-1.6.17 lxml-5.3.0 mpmath-1.3.0 numpy-1.26.4 opencv-python-headless-4.11.0.86 packaging-22.0 pandas-1.5.3 portalocker-3.1.1 protobuf-3.20.3 py-cpuinfo-9.0.0 pycocotools-2.0.8 python-slugify-8.0.4 sacrebleu-2.5.1 sentencepiece-0.2.0 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tensorflow-probability-0.22.1 tensorflow-text-2.18.1 text-unidecode-1.3 tf-keras-2.18.0 tf-models-official-2.18.0 tf-slim-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.8.0rc0\n",
      "  Downloading tensorflow-2.8.0rc0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (24.12.23)\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (3.12.1)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0rc0)\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (3.20.3)\n",
      "Collecting setuptools<60 (from tensorflow==2.8.0rc0)\n",
      "  Downloading setuptools-59.8.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (1.17.0)\n",
      "Collecting tensorboard<2.8,>=2.7 (from tensorflow==2.8.0rc0)\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0rc0)\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0rc0)\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (0.29.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorflow==2.8.0rc0) (1.68.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.0rc0) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.8,>=2.7->tensorflow==2.8.0rc0) (3.2.2)\n",
      "Downloading tensorflow-2.8.0rc0-cp310-cp310-manylinux2010_x86_64.whl (492.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Downloading setuptools-59.8.0-py3-none-any.whl (952 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.8/952.8 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-estimator-nightly, keras, tensorboard-data-server, setuptools, keras-preprocessing, tensorboard, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.8.0\n",
      "    Uninstalling keras-3.8.0:\n",
      "      Successfully uninstalled keras-3.8.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.6.0\n",
      "    Uninstalling setuptools-75.6.0:\n",
      "      Successfully uninstalled setuptools-75.6.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires tensorflow<3,>=2.11.0, but you have tensorflow 2.8.0rc0 which is incompatible.\n",
      "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.8.0rc0 which is incompatible.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.8.0rc0 which is incompatible.\n",
      "tf-models-official 2.18.0 requires tensorflow~=2.18.0, but you have tensorflow 2.8.0rc0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.8.0 keras-preprocessing-1.1.2 setuptools-59.8.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorflow-2.18.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.8.0rc0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT4lByFg-I_r"
   },
   "source": [
    "Define the optimizer and loss function for the learning model. Compute the loss as a vector of losses per-example rather than as the mean over a minibatch to support gradient manipulation over each training point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'estimator_export' from 'tensorflow.python.util.tf_export' (/home/jupyter/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_privacy\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_privacy/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;66;03m# TensorFlow v1 imports\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_privacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;66;03m# Analysis\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_privacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprivacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute_dp_sgd_privacy_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_dp_sgd_privacy\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_privacy/v1/__init__.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;66;03m# Estimators\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_privacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprivacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DNNClassifier \u001b[38;5;28;01mas\u001b[39;00m DNNClassifierV1\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;66;03m# Optimizers\u001b[39;00m\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_privacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprivacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdp_optimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPAdagradGaussianOptimizer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_privacy/privacy/estimators/v1/dnn.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"DP version of DNNClassifiers v1.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_privacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprivacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m head \u001b[38;5;28;01mas\u001b[39;00m head_lib\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcanned\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dnn\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_privacy/privacy/estimators/v1/head.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lookup_ops  \u001b[38;5;66;03m# pylint: disable=g-direct-tensorflow-import\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-deprecated-tf-checker\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_fn\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcanned\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m head \u001b[38;5;28;01mas\u001b[39;00m head_lib\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcanned\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metric_keys\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/model_fn.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_tracer\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_utils\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_export\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmode_keys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModeKeys\n\u001b[1;32m     31\u001b[0m LOSS_METRIC_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'estimator_export' from 'tensorflow.python.util.tf_export' (/home/jupyter/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow_privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bqBvjCf5-ZXy",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow_privacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtensorflow_privacy\u001b[49m\u001b[38;5;241m.\u001b[39mDPKerasSGDOptimizer(\n\u001b[1;32m      2\u001b[0m     l2_norm_clip\u001b[38;5;241m=\u001b[39ml2_norm_clip,\n\u001b[1;32m      3\u001b[0m     noise_multiplier\u001b[38;5;241m=\u001b[39mnoise_multiplier,\n\u001b[1;32m      4\u001b[0m     num_microbatches\u001b[38;5;241m=\u001b[39mnum_microbatches,\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(\n\u001b[1;32m      9\u001b[0m     reduction\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mReduction\u001b[38;5;241m.\u001b[39mNONE\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorflow_privacy' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate,\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    reduction=tf.losses.Reduction.NONE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI_3nXzEGmrP"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4iV03VqG1Bo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_data, test_labels),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kkzQH2LXNjF"
   },
   "source": [
    "## Measure the differential privacy guarantee\n",
    "\n",
    "Perform a privacy analysis to measure the DP guarantee achieved by a training algorithm. Knowing the level of DP achieved enables the objective comparison of two training runs to determine which of the two is more privacy-preserving. At a high level, the privacy analysis measures how much a potential adversary can improve their guess about properties of any individual training point by observing the outcome of the training procedure (e.g., model updates and parameters). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL7_lX5sHCTI"
   },
   "source": [
    "This guarantee is sometimes referred to as the **privacy budget**. A lower privacy budget bounds more tightly an adversary's ability to improve their guess. This ensures a stronger privacy guarantee. Intuitively, this is because it is harder for a single training point to affect the outcome of learning: for instance, the information contained in the training point cannot be memorized by the ML algorithm and the privacy of the individual who contributed this training point to the dataset is preserved.\n",
    "\n",
    "In this tutorial, the privacy analysis is performed in the framework of Rényi Differential Privacy (RDP), which is a relaxation of pure DP based on [this paper](https://arxiv.org/abs/1702.07476) that is particularly well suited for DP-SGD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUEk25pgmnm-"
   },
   "source": [
    "Two metrics are used to express the DP guarantee of an ML algorithm:\n",
    "\n",
    "1.   Delta ($\\delta$) - Bounds the probability of the privacy guarantee not holding. A rule of thumb is to set it to be less than the inverse of the size of the training dataset. In this tutorial, it is set to $10^{-5}$ as the MNIST dataset has 60,000 training points.\n",
    "2.   Epsilon ($\\epsilon$) - This is the privacy budget. It measures the strength of the privacy guarantee (or maximum tolerance for revealing information on input data) by bounding how much the probability of a particular model output can vary by including (or excluding) a single training point. A smaller value for $\\epsilon$ implies a better privacy guarantee. However, the $\\epsilon$ value is only an upper bound and a large value could still mean good privacy in practice.\n",
    "\n",
    "For more detail about the mathematical definition of $(\\epsilon, \\delta)$-differential privacy, see the original [DP-SGD paper](https://arxiv.org/pdf/1607.00133.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PczVdKsGyRQM"
   },
   "source": [
    "Tensorflow Privacy provides a tool, `compute_dp_sgd_privacy`, to compute the value of $\\epsilon$ given a fixed value of $\\delta$ and the following hyperparameters from the training process:\n",
    "\n",
    "1.   The total number of points in the training data, `n`.\n",
    "2. The `batch_size`.\n",
    "3.   The `noise_multiplier`.\n",
    "4. The number of `epochs` of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ws8-nVuVDgtJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpsgd_statement = compute_dp_sgd_privacy.compute_dp_sgd_privacy_statement(\n",
    "    number_of_examples=train_data.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    used_microbatching=False,\n",
    "    num_epochs=epochs,\n",
    "    delta=1e-5,\n",
    ")\n",
    "\n",
    "print(dpsgd_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-KyttEWFRDc"
   },
   "source": [
    "The tool reports $\\epsilon$ value for the hyperparameters chosen above, including $\\delta=10^{-5}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification_privacy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
