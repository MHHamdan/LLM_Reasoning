{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy0nl6LMiUWl"
      },
      "source": [
        "### Comprehensive Guide to LangChain: Building Advanced LLM Applications\n",
        "\n",
        "#### [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc8SFfHBiUWp"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP-roffpiUWq",
        "outputId": "153fa7ec-aa4b-4502-98dd-a37fcbb3fc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai chromadb tiktoken unstructured wikipedia google-search-results langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joyfvm3ziUWr"
      },
      "source": [
        "## Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FL-kb5yTiUWs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.agents import load_tools, initialize_agent, AgentType\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF9OFGsUiUWs"
      },
      "source": [
        "## Set Up API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1eZ33OBlzYr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RofQJtrSiUWt"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"sk-proj-00000-000-00-00\"  # Replace with your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "llm = OpenAI(temperature=0.7)\n",
        "chat_model = ChatOpenAI(temperature=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvuDSfwciUWt"
      },
      "source": [
        "# 1. Basic LLM Interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxj0s-cEiUWu",
        "outputId": "1c3c35b1-b347-46c5-8d5d-e4cdc3af9124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic LLM Response:\n",
            "\n",
            "The capital of Canada is Ottawa.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Chat Model Response:\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ],
      "source": [
        "def test_llm_responses():\n",
        "    print(\"Basic LLM Response:\")\n",
        "    response = llm.predict(\"What is the capital of Canada?\")\n",
        "    print(response)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    print(\"Chat Model Response:\")\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "        HumanMessage(content=\"What is the capital of Canada?\")\n",
        "    ]\n",
        "    response = chat_model.predict_messages(messages)\n",
        "    print(response.content)\n",
        "\n",
        "test_llm_responses()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7USCNKmIiUWu"
      },
      "source": [
        "# 2. Working with Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJdh5pXbiUWv",
        "outputId": "97f70a5d-9807-4d21-ffe4-be92abb39994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Prompt Result:\n",
            "\n",
            "\n",
            "Artificial intelligence (AI) is a branch of computer science that focuses on creating machines that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. This is achieved through the development of algorithms and computer systems that can analyze and interpret data, recognize patterns, and adapt to new situations. AI has applications in various fields, including robotics, healthcare, finance, and transportation, and has the potential to greatly improve efficiency and productivity in these areas. However, there are also concerns about the potential impact of AI on the job market and society as a whole. Ongoing research and advancements in AI technology continue to push the boundaries of what is possible and raise ethical questions about the role of machines in our daily lives. \n",
            "\n",
            "==================================================\n",
            "\n",
            "Detailed Prompt Result:\n",
            "\n",
            "\n",
            "Artificial intelligence, or AI, is a rapidly developing field of computer science that focuses on creating intelligent machines that can perform tasks typically requiring human intelligence. This includes tasks such as speech recognition, decision-making, visual perception, and even creativity. AI has the potential to revolutionize various industries, including healthcare, finance, and transportation, by automating processes and improving efficiency.\n",
            "\n",
            "AI technology is based on the concept of machine learning, where computers are programmed to learn from data and improve their performance without explicit instructions. This allows AI systems to adapt and evolve, making them more accurate and efficient over time. With advancements in AI, machines can now perform complex tasks better than humans, leading to concerns about job displacement. However, AI also has the potential to enhance human capabilities, enabling us to focus on more complex and creative tasks. As AI continues to evolve, it is crucial for businesses to understand its capabilities and potential impact on their industries. Proper integration and utilization of AI can lead to significant advancements and benefits for society. \n"
          ]
        }
      ],
      "source": [
        "def demonstrate_prompt_templates():\n",
        "    basic_prompt = PromptTemplate(\n",
        "        input_variables=[\"topic\"],\n",
        "        template=\"Write a brief summary about {topic}.\"\n",
        "    )\n",
        "    detailed_prompt = PromptTemplate(\n",
        "        input_variables=[\"topic\", \"tone\", \"length\"],\n",
        "        template=\"Write a {length} summary about {topic} in a {tone} tone.\"\n",
        "    )\n",
        "    print(\"Basic Prompt Result:\")\n",
        "    print(llm.predict(basic_prompt.format(topic=\"artificial intelligence\")))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    print(\"Detailed Prompt Result:\")\n",
        "    print(llm.predict(detailed_prompt.format(\n",
        "        topic=\"artificial intelligence\", tone=\"professional\", length=\"two-paragraph\"\n",
        "    )))\n",
        "\n",
        "demonstrate_prompt_templates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAFUbhIDiUWv"
      },
      "source": [
        "# 3. Creating Advanced Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jURQ7nRziUWw",
        "outputId": "094fbf25-8560-4684-94e5-d424d722ff8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Blog Title: \n",
            "\n",
            "\"Combatting Global Warming: Reducing Greenhouse Gases and Our Carbon Footprint with Renewable Energy in the Face of Extreme Weather Events\"\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def multi_step_chain():\n",
        "    # Step 1: Generate keywords for a topic\n",
        "    keyword_prompt = PromptTemplate(\n",
        "        input_variables=[\"topic\"],\n",
        "        template=\"Generate 5 keywords related to {topic}.\"\n",
        "    )\n",
        "    keyword_chain = LLMChain(llm=llm, prompt=keyword_prompt, output_key=\"keywords\")\n",
        "\n",
        "    # Step 2: Use keywords to create a blog title\n",
        "    title_prompt = PromptTemplate(\n",
        "        input_variables=[\"keywords\"],\n",
        "        template=\"Create a blog title using these keywords: {keywords}\"\n",
        "    )\n",
        "    title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key=\"blog_title\")\n",
        "\n",
        "    # Combine chains using SequentialChain\n",
        "    chain = SequentialChain(\n",
        "        chains=[keyword_chain, title_chain],\n",
        "        input_variables=[\"topic\"],  # Initial input to the chain\n",
        "        output_variables=[\"blog_title\"]  # Final output of the chain\n",
        "    )\n",
        "\n",
        "    # Test the chain\n",
        "    result = chain.run({\"topic\": \"climate change\"})\n",
        "    print(\"Generated Blog Title:\", result)\n",
        "\n",
        "multi_step_chain()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQjCIuyXl1Dq"
      },
      "source": [
        "# 4. Using LangChain for Summarization Tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRY0oBTCjWF6",
        "outputId": "0fb8f32f-6e3a-463e-8124-c66984aaa20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document Summary:\n",
            "\n",
            "\n",
            "Climate change is caused by human activities, specifically the burning of fossil fuels, which leads to increased greenhouse gas concentrations in the atmosphere. This results in global warming and various environmental changes, such as rising sea levels, melting glaciers, and impacts on ecosystems. To address climate change, both mitigation efforts (reducing emissions) and adaptation strategies (preparing for current impacts) are needed.\n"
          ]
        }
      ],
      "source": [
        "def summarize_document():\n",
        "    # Load a sample document\n",
        "    document_text = \"\"\"\n",
        "    Climate change refers to long-term alterations in temperature, precipitation, wind patterns, and other elements of the Earth's climate system.\n",
        "    It is primarily driven by human activities, particularly the burning of fossil fuels, which increases greenhouse gas concentrations in the atmosphere.\n",
        "    These gases trap heat, leading to global warming and a host of other environmental changes, including rising sea levels, melting glaciers, and disruptions to ecosystems.\n",
        "    Addressing climate change requires a combination of mitigation efforts, such as reducing emissions, and adaptation strategies, such as preparing for the impacts already underway.\n",
        "    \"\"\"\n",
        "\n",
        "    # Split the document into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "    chunks = text_splitter.split_text(document_text)\n",
        "\n",
        "    # Summarize each chunk and combine\n",
        "    summarization_prompt = PromptTemplate(\n",
        "        input_variables=[\"chunk\"],\n",
        "        template=\"Summarize the following text: {chunk}\"\n",
        "    )\n",
        "    summarization_chain = LLMChain(llm=llm, prompt=summarization_prompt)\n",
        "\n",
        "    summary = \"\\n\".join([summarization_chain.run({\"chunk\": chunk}) for chunk in chunks])\n",
        "    print(\"Document Summary:\")\n",
        "    print(summary)\n",
        "\n",
        "summarize_document()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KES-U4jPm25k"
      },
      "source": [
        "\n",
        "# 5. Using LangChain for Q&A with Custom Data\n",
        "\n",
        "## Build a Question-Answering System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhpW_-uVm1lL",
        "outputId": "602e6da6-1e59-4228-d38a-91b7255a24f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is Artificial Intelligence?\n",
            "Answer:  Artificial Intelligence is a field of computer science focused on creating systems capable of performing tasks that usually require human intelligence.\n"
          ]
        }
      ],
      "source": [
        "def qa_with_custom_data():\n",
        "    # Sample document content\n",
        "    document_content = \"\"\"\n",
        "    Artificial Intelligence (AI) is a field of computer science focused on creating systems capable of performing tasks that usually require human intelligence.\n",
        "    These tasks include natural language understanding, image recognition, decision-making, and more.\n",
        "    Advances in AI have been driven by machine learning techniques, particularly deep learning, which involves training neural networks on large datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    # Split and process the document\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
        "    chunks = text_splitter.split_text(document_content)\n",
        "\n",
        "    # Embed the document\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = Chroma.from_texts(chunks, embeddings)\n",
        "\n",
        "    # Create a retriever\n",
        "    retriever = vectorstore.as_retriever()\n",
        "\n",
        "    # Define a QA chain\n",
        "    qa_prompt = PromptTemplate(\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "        template=\"Given the following context, answer the question.\\nContext: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "    )\n",
        "    qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
        "\n",
        "    # Ask a question\n",
        "    question = \"What is Artificial Intelligence?\"\n",
        "    relevant_context = retriever.get_relevant_documents(question)[0].page_content\n",
        "    answer = qa_chain.run({\"context\": relevant_context, \"question\": question})\n",
        "\n",
        "    print(\"Question:\", question)\n",
        "    print(\"Answer:\", answer)\n",
        "\n",
        "qa_with_custom_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p41x3rsnUvJ"
      },
      "source": [
        "# 6. Question Answering with Images\n",
        "\n",
        "## Building an Image-Based Q&A System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d1YBgwbo7cC",
        "outputId": "17b56cc1-c4a4-4eca-edc9-db6a3db32444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ],
      "source": [
        "#!pip -q install pdfminer\n",
        "#!pip uninstall -y pdfminer.six unstructured\n",
        "#!pip install \"pdfminer.six<20221105\" \"unstructured==0.10.12\"\n",
        "!pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5YRobDnl7j6",
        "outputId": "f9fa7928-95e1-4978-e33b-11a238fd66c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIHp9mvkngPE",
        "outputId": "c3755bef-c56c-4c03-e9ee-1ec496c295bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What information is provided in the image?\n",
            "Answer: The image provides text that reads \"waa\" and \"ry ae\".\n"
          ]
        }
      ],
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "def qa_with_image():\n",
        "    image_path = \"/content/sign.webp\"\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Extract text with pytesseract directly\n",
        "    extracted_text = pytesseract.image_to_string(image)\n",
        "\n",
        "    llm = ChatOpenAI(model_name=\"gpt-4\")\n",
        "\n",
        "    qa_prompt = PromptTemplate(\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "        template=(\n",
        "            \"Given the following context extracted from an image, \"\n",
        "            \"answer the question.\\nContext: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "        )\n",
        "    )\n",
        "    qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
        "\n",
        "    question = \"What information is provided in the image?\"\n",
        "    answer = qa_chain.run({\"context\": extracted_text, \"question\": question})\n",
        "\n",
        "    print(\"Question:\", question)\n",
        "    print(\"Answer:\", answer)\n",
        "\n",
        "qa_with_image()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GEY6UdetSjr"
      },
      "source": [
        "# 7. Question Answering with Videos\n",
        "\n",
        "## Building a Video-Based Q&A System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTAfjWeatT6y"
      },
      "outputs": [],
      "source": [
        "def qa_with_video():\n",
        "    import cv2\n",
        "    from langchain.document_loaders import UnstructuredVideoLoader\n",
        "\n",
        "    # Load a video\n",
        "    video_path = \"sample_video.mp4\"  # Replace with your video file path\n",
        "\n",
        "    # Extract text from the video\n",
        "    video_loader = UnstructuredVideoLoader(file_path=video_path)\n",
        "    extracted_text = video_loader.load()[0].page_content\n",
        "\n",
        "    # Define a QA prompt\n",
        "    qa_prompt = PromptTemplate(\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "        template=\"Given the following context extracted from a video, answer the question.\\nContext: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "    )\n",
        "    qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
        "\n",
        "    # Ask a question\n",
        "    question = \"What is described in the video?\"\n",
        "    answer = qa_chain.run({\"context\": extracted_text, \"question\": question})\n",
        "\n",
        "    print(\"Question:\", question)\n",
        "    print(\"Answer:\", answer)\n",
        "\n",
        "qa_with_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSjokY7Srxu8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
